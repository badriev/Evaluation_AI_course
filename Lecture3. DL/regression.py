# regression.py

# =============================================================================
# MSE –î–õ–Ø –ì–õ–£–ë–û–ö–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø - –†–ï–ê–õ–¨–ù–´–ô –î–ê–¢–ê–°–ï–¢ –û –ù–ï–î–í–ò–ñ–ò–ú–û–°–¢–ò (–¢–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –º–æ–¥–µ–ª—å)
# =============================================================================
import pandas as pd
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow as tf
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.datasets import fetch_california_housing
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import time


class TimeCallback(keras.callbacks.Callback):
    """Callback –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è"""

    def __init__(self, print_every=5):
        super().__init__()
        self.print_every = print_every

    def on_train_begin(self, logs=None):
        self.start_time = time.time()

    def on_epoch_end(self, epoch, logs=None):
        if epoch % self.print_every == 0:
            elapsed_time = time.time() - self.start_time
            print(f"‚è±Ô∏è –≠–ø–æ—Ö–∞ {epoch + 1}: {elapsed_time:.1f}s –æ–±—â–µ–µ –≤—Ä–µ–º—è")


class DataLoader:
    """–ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""

    def __init__(self):
        self.data = None
        self.scaler_X = StandardScaler()
        self.scaler_y = StandardScaler()

    def load_california_housing(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç California Housing"""
        print("\nüìä –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç California Housing...")

        california_housing = fetch_california_housing()
        feature_names = california_housing.feature_names
        X = california_housing.data
        y = california_housing.target

        df = pd.DataFrame(X, columns=feature_names)
        df['target'] = y
        self.data = df

        return df

    def prepare_data(self, test_size=0.2, val_size=0.25, random_state=42):
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

        Args:
            test_size: —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏
            val_size: —Ä–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ (–æ—Ç –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö)
            random_state: seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

        Returns:
            –ö–æ—Ä—Ç–µ–∂ —Å –æ–±—É—á–∞—é—â–∏–º–∏, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –∏ —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        """
        print("\nüîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è...")

        X = self.data.drop('target', axis=1).values
        y = self.data['target'].values

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        X_scaled = self.scaler_X.fit_transform(X)
        y_scaled = self.scaler_y.fit_transform(y.reshape(-1, 1)).flatten()

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        X_temp, X_test, y_temp, y_test = train_test_split(
            X_scaled, y_scaled, test_size=test_size, random_state=random_state
        )
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=val_size, random_state=random_state
        )

        print(f"üìä –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X_train.shape}")
        print(f"üìä –†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_val.shape}")
        print(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_test.shape}")

        return X_train, X_val, X_test, y_train, y_val, y_test


class ModelBuilder:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""

    @staticmethod
    def create_deep_housing_model(input_dim):
        """
        –°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è MSE)
        """
        model = keras.Sequential([
            layers.Dense(64, activation='relu', input_shape=(input_dim,)),
            layers.Dropout(0.2),
            layers.Dense(32, activation='relu'),
            layers.Dropout(0.2),
            layers.Dense(16, activation='relu'),
            layers.Dense(1, activation='linear')
        ])

        optimizer = keras.optimizers.Adam(learning_rate=0.01)

        model.compile(
            optimizer=optimizer,
            loss='mse',
            metrics=['mae']
        )

        return model, "Standard MSE"


class ModelTrainer:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""

    def __init__(self):
        self.models = {}
        self.histories = {}
        self.training_times = {}

    def setup_callbacks(self):
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç callbacks –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        early_stopping = keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True,
            verbose=1
        )

        reduce_lr = keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=3,
            min_lr=1e-6,
            verbose=1
        )

        time_callback = TimeCallback(print_every=5)

        return [early_stopping, reduce_lr, time_callback]

    def train_model(self, model, model_name, X_train, y_train, X_val, y_val, epochs=20, batch_size=256):
        """
        –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å
        """
        print(f"\n–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model_name}...")
        start_time = time.time()

        callbacks = self.setup_callbacks()

        history = model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=1
        )

        training_time = time.time() - start_time

        self.models[model_name] = model
        self.histories[model_name] = history
        self.training_times[model_name] = training_time

        print(
            f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {model_name}: {training_time:.2f} —Å–µ–∫—É–Ω–¥")
        return history

    def diagnose_training_time(self):
        """–î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è"""
        total_time = sum(self.training_times.values())
        print(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥")
        if total_time > 300:
            print(
                f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: {total_time:.1f}s ‚Äî —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ. –ü—Ä–æ–≤–µ—Ä—å —Ä–∞–∑–º–µ—Ä—ã –º–æ–¥–µ–ª–∏/–¥–∞–Ω–Ω—ã–µ/TF.")
        elif total_time > 180:
            print(f"‚ö†Ô∏è {total_time:.1f}s ‚Äî –º–æ–∂–Ω–æ —É—Å–∫–æ—Ä–∏—Ç—å.")
        else:
            print(f"‚úÖ –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ: {total_time:.1f}s")


class ModelEvaluator:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏"""

    def __init__(self, scaler_y):
        self.scaler_y = scaler_y
        self.metrics = {}

    def evaluate_model(self, model, model_name, X_test, y_test, training_time):
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏
        """
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü–∞—Ö —Ç–∞—Ä–≥–µ—Ç–∞)
        y_pred = model.predict(X_test, verbose=0)

        # –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (–≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –∏—Å—Ö–æ–¥–Ω–æ–π —à–∫–∞–ª–µ –¥–∞—Ç–∞—Å–µ—Ç–∞: "—Å–æ—Ç–Ω–∏ —Ç—ã—Å—è—á $")
        y_test_original_units = self.scaler_y.inverse_transform(
            y_test.reshape(-1, 1)
        ).flatten()
        y_pred_original_units = self.scaler_y.inverse_transform(
            y_pred
        ).flatten()

        # –ü–ï–†–ï–í–û–î –í –î–û–õ–õ–ê–†–´: 1 –µ–¥. = 100 000 $
        y_test_dollars = y_test_original_units * 100_000.0
        y_pred_dollars = y_pred_original_units * 100_000.0

        # –ú–µ—Ç—Ä–∏–∫–∏ –≤ –¥–æ–ª–ª–∞—Ä–∞—Ö
        mse = mean_squared_error(y_test_dollars, y_pred_dollars)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test_dollars, y_pred_dollars)
        r2 = r2_score(y_test_dollars, y_pred_dollars)

        metrics = {
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'r2': r2,
            'training_time': training_time,
            # —Ö—Ä–∞–Ω–∏–º –º–∞—Å—Å–∏–≤—ã —Ç–æ–∂–µ –≤ –¥–æ–ª–ª–∞—Ä–∞—Ö, —á—Ç–æ–±—ã –≤—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏/–ø–µ—á–∞—Ç—å –±—ã–ª–∏ –≤ $ –¥–∞–ª—å—à–µ
            'y_test_original': y_test_dollars,
            'y_pred_original': y_pred_dollars
        }
        self.metrics[model_name] = metrics
        return metrics

    def print_metrics(self, model_name):
        """–ü–µ—á–∞—Ç–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏ (–≤ —Ä–µ–∞–ª—å–Ω—ã—Ö $)"""
        metrics = self.metrics[model_name]
        print(f"\nüîπ {model_name}:")
        print(f"   ‚Ä¢ MSE:  {metrics['mse']:.2f} $^2")
        print(f"   ‚Ä¢ RMSE: {metrics['rmse']:.2f} $")
        print(f"   ‚Ä¢ MAE:  {metrics['mae']:.2f} $")
        print(f"   ‚Ä¢ R¬≤:   {metrics['r2']:.4f}")


class DataVisualizer:
    """–ö–ª–∞—Å—Å –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

    def __init__(self, data_loader):
        self.data_loader = data_loader

    def plot_results(self, trainer, evaluator):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏"""
        plt.figure(figsize=(20, 12))

        # –ì—Ä–∞—Ñ–∏–∫ 1: –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è - Loss
        plt.subplot(2, 4, 1)
        for model_name, history in trainer.histories.items():
            plt.plot(history.history['loss'],
                     label=f'{model_name} (–æ–±—É—á–µ–Ω–∏–µ)', linewidth=2)
            plt.plot(history.history['val_loss'],
                     label=f'{model_name} (–≤–∞–ª–∏–¥–∞—Ü–∏—è)', linewidth=2)
        plt.title('–ò—Å—Ç–æ—Ä–∏—è MSE Loss')
        plt.xlabel('–≠–ø–æ—Ö–∞')
        plt.ylabel('MSE Loss')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # –ì—Ä–∞—Ñ–∏–∫ 2: –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è - MAE
        plt.subplot(2, 4, 2)
        for model_name, history in trainer.histories.items():
            plt.plot(history.history['mae'], label=model_name, linewidth=2)
        plt.title('Mean Absolute Error')
        plt.xlabel('–≠–ø–æ—Ö–∞')
        plt.ylabel('MAE')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # –ì—Ä–∞—Ñ–∏–∫ 3: –ò—Å—Ç–∏–Ω–∞ vs –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        plt.subplot(2, 4, 3)
        (model_name, metrics), = evaluator.metrics.items()
        y_test = metrics['y_test_original']
        y_pred = metrics['y_pred_original']
        plt.scatter(y_test, y_pred, alpha=0.5)
        plt.plot([y_test.min(), y_test.max()],
                 [y_test.min(), y_test.max()], 'r--', lw=2)
        plt.xlabel('–ò—Å—Ç–∏–Ω–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å ($)')
        plt.ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å ($)')
        plt.title(f'{model_name}\nR¬≤ = {metrics["r2"]:.4f}')
        plt.grid(True, alpha=0.3)

        # –ì—Ä–∞—Ñ–∏–∫ 4: –û—Å—Ç–∞—Ç–∫–∏ vs –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        plt.subplot(2, 4, 5)
        residuals = y_test - y_pred
        plt.scatter(y_pred, residuals, alpha=0.5)
        plt.axhline(y=0, color='r', linestyle='--', lw=2)
        plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å ($)')
        plt.ylabel('–û—Å—Ç–∞—Ç–∫–∏ ($)')
        plt.title('–û—Å—Ç–∞—Ç–∫–∏ vs –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è')
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()


class MSEDemo:
    """–ö–ª–∞—Å—Å –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã MSE"""

    @staticmethod
    def demonstrate_mse_on_batch(evaluator):
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã MSE –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –±–∞—Ç—á–µ"""
        print("\nüîç –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø MSE –ù–ê –†–ï–ê–õ–¨–ù–û–ú –ë–ê–¢–ß–ï:")
        print("="*70)

        if not evaluator.metrics:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏")
            return

        # –ë–µ—Ä–µ–º –º–µ—Ç—Ä–∏–∫–∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        (model_name, metrics), = evaluator.metrics.items()
        y_true_original = metrics['y_test_original']
        y_pred_original = metrics['y_pred_original']

        batch_size = min(10, len(y_true_original))
        batch_indices = np.random.choice(
            len(y_true_original), batch_size, replace=False)
        y_true_batch = y_true_original[batch_indices]
        y_pred_batch = y_pred_original[batch_indices]

        print(f"–ú–æ–¥–µ–ª—å: {model_name}")
        print(f"–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size}")
        print(f"{'‚Ññ':<3} {'–ò—Å—Ç–∏–Ω–Ω–∞—è —Ü–µ–Ω–∞ ($)':<20} {'–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è ($)':<20} {'–û—à–∏–±–∫–∞ ($)':<15} {'–û—à–∏–±–∫–∞¬≤ ($¬≤)':<18}")
        print("-" * 70)

        total_squared_error = 0.0
        for i in range(batch_size):
            true_price = y_true_batch[i]
            pred_price = y_pred_batch[i]
            error = true_price - pred_price
            squared_error = error ** 2
            total_squared_error += squared_error
            print(
                f"{i+1:<3} {true_price:<15.2f} {pred_price:<15.2f} {error:<12.2f} {squared_error:<15.2f}")

        mse_batch = total_squared_error / batch_size
        print(f"\nMSE –¥–ª—è –±–∞—Ç—á–∞: {mse_batch:.2f} $^2")


class HousingAnalyzer:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"""

    def __init__(self):
        self.data_loader = DataLoader()
        self.model_builder = ModelBuilder()
        self.trainer = ModelTrainer()
        self.evaluator = None
        self.visualizer = None
        self.mse_demo = MSEDemo()

    def run_analysis(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        print("="*70)
        print("üè† MSE –î–õ–Ø –ì–õ–£–ë–û–ö–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø - –†–ï–ê–õ–¨–ù–´–ô –î–ê–¢–ê–°–ï–¢ –û –ù–ï–î–í–ò–ñ–ò–ú–û–°–¢–ò")
        print("="*70)

        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.data_loader.load_california_housing()

        # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X_train, X_val, X_test, y_train, y_val, y_test = self.data_loader.prepare_data()

        # 3. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ü–µ–Ω—â–∏–∫–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        self.evaluator = ModelEvaluator(self.data_loader.scaler_y)
        self.visualizer = DataVisualizer(self.data_loader)

        # 4. –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
        print("\nüß† –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –≥–ª—É–±–æ–∫–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ (Standard MSE)...")
        model, loss_name = self.model_builder.create_deep_housing_model(
            X_train.shape[1])

        print(f"\nüèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏:")
        model.summary()

        print("\nüöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        history = self.trainer.train_model(
            model, "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è MSE", X_train, y_train, X_val, y_val
        )

        # 5. –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
        self.trainer.diagnose_training_time()

        # 6. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
        print("\nüéØ –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏...")
        _ = self.evaluator.evaluate_model(
            model, "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è MSE", X_test, y_test,
            self.trainer.training_times["–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è MSE"]
        )

        # 7. –ü–µ—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ù–ê –†–ï–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–•:")
        print("="*60)
        self.evaluator.print_metrics("–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è MSE")

        # 8. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        self.visualizer.plot_results(self.trainer, self.evaluator)

        # 9. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è MSE
        self.mse_demo.demonstrate_mse_on_batch(self.evaluator)


# ============================================================================
# –ó–ê–ü–£–°–ö –ü–†–û–ì–†–ê–ú–ú–´
# ============================================================================

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞"""
    analyzer = HousingAnalyzer()
    analyzer.run_analysis()

    print("\n" + "="*80)
    print("–ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
    print("="*80)


if __name__ == "__main__":
    main()
