import json
import asyncio
from typing import List, Dict, Any, Optional, Tuple
from abc import ABC, abstractmethod
import logging
from pathlib import Path

# ChromaDB
try:
    import chromadb
    from chromadb.config import Settings as ChromaSettings
except ImportError:
    chromadb = None

# Pinecone
try:
    import pinecone
except ImportError:
    pinecone = None

# FAISS
try:
    import faiss
    import numpy as np
except ImportError:
    faiss = None
    np = None

from app.config import settings
from app.models.document import DocumentChunk

logger = logging.getLogger(__name__)


class BaseVectorStore(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â"""

    @abstractmethod
    async def add_documents(self, chunks: List[DocumentChunk]) -> bool:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
        pass

    @abstractmethod
    async def search(self, query_embedding: List[float], top_k: int = 5, **kwargs) -> List[Dict[str, Any]]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É —Ö—Ä–∞–Ω–∏–ª–∏—â—É"""
        pass

    @abstractmethod
    async def delete_document(self, document_id: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        pass

    @abstractmethod
    async def get_collection_info(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        pass


class ChromaVectorStore(BaseVectorStore):
    """–í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ ChromaDB"""

    def __init__(self, persist_directory: str = None, collection_name: str = "rag_documents"):
        if not chromadb:
            raise ImportError("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ chromadb: pip install chromadb")

        self.persist_directory = persist_directory or settings.CHROMA_PERSIST_DIRECTORY
        self.collection_name = collection_name

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        Path(self.persist_directory).mkdir(parents=True, exist_ok=True)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç
        self.client = chromadb.PersistentClient(
            path=self.persist_directory,
            settings=ChromaSettings(anonymized_telemetry=False)
        )

        # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"description": "RAG documents collection"}
        )

        logger.info(f"ChromaDB –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.persist_directory}")

    async def add_documents(self, chunks: List[DocumentChunk]) -> bool:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ ChromaDB"""
        if not chunks:
            return True

        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è ChromaDB
            ids = []
            embeddings = []
            documents = []
            metadatas = []

            for chunk in chunks:
                if chunk.embedding is None:
                    logger.warning(f"–ß–∞–Ω–∫ {chunk.id} –Ω–µ –∏–º–µ–µ—Ç embedding")
                    continue

                ids.append(chunk.id)
                embeddings.append(chunk.embedding)
                documents.append(chunk.text)
                metadatas.append({
                    "document_id": chunk.document_id,
                    "chunk_index": chunk.chunk_index,
                    **chunk.metadata
                })

            if not ids:
                logger.warning("–ù–µ—Ç —á–∞–Ω–∫–æ–≤ —Å embeddings –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è")
                return False

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
            await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.collection.add(
                    ids=ids,
                    embeddings=embeddings,
                    documents=documents,
                    metadatas=metadatas
                )
            )

            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(ids)} —á–∞–Ω–∫–æ–≤ –≤ ChromaDB")
            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ ChromaDB: {e}")
            return False

    async def search(self, query_embedding: List[float], top_k: int = 5, **kwargs) -> List[Dict[str, Any]]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤ ChromaDB"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            total_count = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.collection.count()
            )
            logger.info(f"üîç –ü–æ–∏—Å–∫ –≤ ChromaDB: –≤—Å–µ–≥–æ {total_count} —á–∞–Ω–∫–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏")
            
            if total_count == 0:
                logger.warning("‚ö†Ô∏è  ChromaDB –∫–æ–ª–ª–µ–∫—Ü–∏—è –ü–£–°–¢–ê–Ø!")
                return []
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            logger.info(f"üîé –ó–∞–ø—Ä–æ—Å –ø–æ–∏—Å–∫–∞: top_k={top_k}, embedding_dim={len(query_embedding)}")
            results = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.collection.query(
                    query_embeddings=[query_embedding],
                    n_results=min(top_k, total_count),
                    include=["documents", "metadatas", "distances"]
                )
            )

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            search_results = []
            if results['ids'] and results['ids'][0]:
                logger.info(f"üìä ChromaDB –≤–µ—Ä–Ω—É–ª–∞ {len(results['ids'][0])} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                
                for i in range(len(results['ids'][0])):
                    distance = results['distances'][0][i]
                    similarity = 1 - distance
                    
                    result = {
                        "chunk_id": results['ids'][0][i],
                        "text": results['documents'][0][i],
                        "metadata": results['metadatas'][0][i],
                        "distance": distance,
                        "similarity": similarity
                    }
                    
                    logger.info(f"   {i+1}. similarity={similarity:.4f}, distance={distance:.4f}, doc={results['metadatas'][0][i].get('source', 'Unknown')}")
                    
                    search_results.append(result)
            else:
                logger.warning("‚ö†Ô∏è  ChromaDB –≤–µ—Ä–Ω—É–ª–∞ 0 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

            return search_results

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ ChromaDB: {e}", exc_info=True)
            return []

    async def delete_document(self, document_id: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ ChromaDB"""
        try:
            # –ò—â–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            results = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.collection.get(
                    where={"document_id": document_id},
                    include=["metadatas"]
                )
            )

            if results['ids']:
                # –£–¥–∞–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏
                await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: self.collection.delete(ids=results['ids'])
                )
                logger.info(
                    f"–£–¥–∞–ª–µ–Ω–æ {len(results['ids'])} —á–∞–Ω–∫–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {document_id}")

            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ ChromaDB: {e}")
            return False

    async def get_collection_info(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ ChromaDB"""
        try:
            count = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.collection.count()
            )

            return {
                "type": "chromadb",
                "collection_name": self.collection_name,
                "total_chunks": count,
                "persist_directory": self.persist_directory
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
            return {"type": "chromadb", "error": str(e)}
    
    
    async def get_document_chunks_from_db(self, document_id: str) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ ChromaDB"""
        try:
            logger.info(f"üìÇ –ü–æ–ª—É—á–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {document_id} –∏–∑ ChromaDB")
            
            results = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.collection.get(
                    where={"document_id": document_id},
                    include=["documents", "metadatas"]
                )
            )
            
            chunks = []
            if results['ids']:
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results['ids'])} —á–∞–Ω–∫–æ–≤")
                
                for i, chunk_id in enumerate(results['ids']):
                    chunks.append({
                        "id": chunk_id,
                        "document_id": document_id,
                        "chunk_index": results['metadatas'][i].get('chunk_index', i),
                        "text": results['documents'][i],
                        "metadata": results['metadatas'][i],
                        "has_embedding": True
                    })
                
                chunks.sort(key=lambda x: x.get('chunk_index', 0))
            
            return chunks
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}", exc_info=True)
            return []


class PineconeVectorStore(BaseVectorStore):
    """–í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ Pinecone"""

    def __init__(self, api_key: str = None, environment: str = None, index_name: str = None):
        if not pinecone:
            raise ImportError(
                "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ pinecone: pip install pinecone-client")

        self.api_key = api_key or settings.PINECONE_API_KEY
        self.environment = environment or settings.PINECONE_ENVIRONMENT
        self.index_name = index_name or settings.PINECONE_INDEX_NAME

        if not all([self.api_key, self.environment, self.index_name]):
            raise ValueError(
                "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å PINECONE_API_KEY, PINECONE_ENVIRONMENT –∏ PINECONE_INDEX_NAME")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Pinecone
        pinecone.init(
            api_key=self.api_key,
            environment=self.environment
        )

        self.index = pinecone.Index(self.index_name)
        logger.info(f"Pinecone –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.index_name}")

    async def add_documents(self, chunks: List[DocumentChunk]) -> bool:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫–∏ –≤ Pinecone"""
        if not chunks:
            return True

        try:
            vectors = []
            for chunk in chunks:
                if chunk.embedding is None:
                    continue

                vectors.append({
                    "id": chunk.id,
                    "values": chunk.embedding,
                    "metadata": {
                        "document_id": chunk.document_id,
                        "chunk_index": chunk.chunk_index,
                        "text": chunk.text,
                        **chunk.metadata
                    }
                })

            if vectors:
                await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: self.index.upsert(vectors=vectors)
                )
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(vectors)} —á–∞–Ω–∫–æ–≤ –≤ Pinecone")

            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ Pinecone: {e}")
            return False

    async def search(self, query_embedding: List[float], top_k: int = 5, **kwargs) -> List[Dict[str, Any]]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤ Pinecone"""
        try:
            results = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.index.query(
                    vector=query_embedding,
                    top_k=top_k,
                    include_metadata=True
                )
            )

            search_results = []
            for match in results['matches']:
                search_results.append({
                    "chunk_id": match['id'],
                    "text": match['metadata'].get('text', ''),
                    "metadata": match['metadata'],
                    "similarity": match['score']
                })

            return search_results

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Pinecone: {e}")
            return []

    async def delete_document(self, document_id: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ Pinecone"""
        try:
            await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.index.delete(filter={"document_id": document_id})
            )
            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ Pinecone: {e}")
            return False

    async def get_collection_info(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–Ω–¥–µ–∫—Å–µ Pinecone"""
        try:
            stats = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.index.describe_index_stats()
            )

            return {
                "type": "pinecone",
                "index_name": self.index_name,
                "total_vectors": stats.get('total_vector_count', 0),
                "dimension": stats.get('dimension', 0)
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ Pinecone: {e}")
            return {"type": "pinecone", "error": str(e)}


class VectorStoreService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞–º–∏"""

    def __init__(self, store: Optional[BaseVectorStore] = None):
        self.store = store or self._create_default_store()

    def _create_default_store(self) -> BaseVectorStore:
        """–°–æ–∑–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        if settings.VECTOR_DB_TYPE == "chroma":
            return ChromaVectorStore()
        elif settings.VECTOR_DB_TYPE == "pinecone":
            return PineconeVectorStore()
        else:
            raise ValueError(
                f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î: {settings.VECTOR_DB_TYPE}")

    async def add_document_chunks(self, chunks: List[DocumentChunk]) -> bool:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
        return await self.store.add_documents(chunks)

    async def search_similar_chunks(
        self,
        query_embedding: List[float],
        top_k: int = None,
        similarity_threshold: float = None
    ) -> List[Dict[str, Any]]:
        """
        –ò—â–µ—Ç –ø–æ—Ö–æ–∂–∏–µ —á–∞–Ω–∫–∏

        Args:
            query_embedding: embedding –∑–∞–ø—Ä–æ—Å–∞
            top_k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            similarity_threshold: –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        top_k = top_k or settings.MAX_RELEVANT_CHUNKS
        similarity_threshold = similarity_threshold or settings.SIMILARITY_THRESHOLD

        results = await self.store.search(query_embedding, top_k)

        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É —Å—Ö–æ–¥—Å—Ç–≤–∞
        filtered_results = []
        for result in results:
            similarity = result.get('similarity', 0)
            if similarity >= similarity_threshold:
                filtered_results.append(result)

        return filtered_results

    async def delete_document_chunks(self, document_id: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        return await self.store.delete_document(document_id)

    async def get_store_info(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
        return await self.store.get_collection_info()
    
    async def get_document_chunks_from_store(self, document_id: str) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
        if isinstance(self.store, ChromaVectorStore):
            return await self.store.get_document_chunks_from_db(document_id)
        else:
            logger.warning(f"–ù–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –¥–ª—è {type(self.store).__name__}")
            return []

    async def test_connection(self) -> bool:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É —Ö—Ä–∞–Ω–∏–ª–∏—â—É"""
        try:
            info = await self.get_store_info()
            return not info.get('error')
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞: {e}")
            return False


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
_vector_store_service: Optional[VectorStoreService] = None


def get_vector_store_service() -> VectorStoreService:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
    global _vector_store_service
    if _vector_store_service is None:
        _vector_store_service = VectorStoreService()
    return _vector_store_service
